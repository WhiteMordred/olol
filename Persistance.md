# Roadmap d'impl√©mentation de la persistance avec TinyDB

## Introduction

Ce document pr√©sente la roadmap d√©taill√©e pour l'impl√©mentation d'un syst√®me de persistance de donn√©es bas√© sur TinyDB dans le projet OLOL. Il d√©crit les √©tapes, les d√©pendances entre les composants et les objectifs √† atteindre √† chaque phase du d√©veloppement.

**Objectifs principaux :**
- Remplacer les structures en m√©moire (verrous, dictionnaires) par une persistance bas√©e sur TinyDB
- Collecter des informations d√©taill√©es sur les ressources mat√©rielles des n≈ìuds
- Mettre en place un m√©canisme robuste de synchronisation des donn√©es
- Assurer une abstraction permettant une migration future vers d'autres syst√®mes de stockage

## Phase 1 : Mise en place de l'infrastructure de persistance

### 1.1 Classe d'abstraction DatabaseManager (‚úì Compl√©t√©)

**Fichier :** `/src/osync/proxy/db/database.py`

La classe d'abstraction [`DatabaseManager`](/src/osync/proxy/db/database.py) a √©t√© impl√©ment√©e avec les fonctionnalit√©s suivantes :
- Interface CRUD compl√®te (Create, Read, Update, Delete)
- Singleton pour acc√®s global √† l'instance
- Gestion des chemins de stockage automatis√©e
- Horodatage automatique des documents
- Support de requ√™tes flexibles

**Relations :**
- Utilis√© par tous les autres composants n√©cessitant une persistance
- Point d'acc√®s unique via la fonction `get_db()`

### 1.2 Ajout de la d√©pendance √† TinyDB (‚úì Compl√©t√©)

**Fichier :** `/pyproject.toml`

La d√©pendance √† TinyDB a √©t√© ajout√©e au fichier pyproject.toml :
```toml
dependencies = [
    # ...autres d√©pendances existantes...
    "tinydb>=4.8.0",
]
```

### 1.3 Sch√©ma des donn√©es

D√©finition du sch√©ma des tables pour la persistance des donn√©es :

#### Table `servers`
```json
{
  "address": "host:port",
  "healthy": true,
  "load": 0.45,
  "last_check": "2025-04-30T14:30:00",
  "first_seen": "2025-04-28T10:15:20",
  "hardware_info": {
    "cpu": { ... },
    "ram": { ... },
    "gpu": { ... },
    "storage": { ... }
  }
}
```

#### Table `models`
```json
{
  "name": "llama3",
  "servers": ["host1:port", "host2:port"],
  "size_gb": 8,
  "parameter_count": "8B",
  "quantization": "Q4_K_M",
  "first_seen": "2025-04-15T08:20:00",
  "last_used": "2025-04-30T14:30:00",
  "usage_count": 157
}
```

#### Table `server_stats`
```json
{
  "server": "host:port",
  "timestamp": "2025-04-30T14:30:00",
  "type": "health|load|latency",
  "value": 0.75
}
```

#### Table `request_stats`
```json
{
  "timestamp": "2025-04-30T14:30:00",
  "period": "hourly|daily|weekly",
  "total_requests": 1458,
  "generate_requests": 857,
  "chat_requests": 523,
  "embedding_requests": 78,
  "average_latency_ms": 235.5
}
```

#### Table `config`
```json
{
  "key": "proxy_settings|load_balancing|retry_policy",
  "value": {},
  "updated_at": "2025-04-30T14:30:00"
}
```

## Phase 2 : Int√©gration au gestionnaire de cluster

### 2.1 Modification du ClusterManager

**Fichier :** `/src/osync/proxy/cluster/manager.py`

**T√¢ches :**
- [ ] Modifier la m√©thode `refresh_cache` pour synchroniser avec TinyDB
- [ ] Modifier `initialize` pour charger les donn√©es depuis TinyDB
- [ ] Ajouter des m√©thodes d√©di√©es pour la persistance des serveurs et mod√®les

**M√©thodes √† modifier :**
```python
def refresh_cache(self):
    """
    Met √† jour le cache des informations du cluster et persiste dans TinyDB.
    """
    # 1. Obtenir les donn√©es du cluster (code existant)
    # 2. Synchroniser avec TinyDB
    # 3. Mettre √† jour le cache local
    
def initialize(self, cluster_config=None):
    """
    Initialise ou r√©initialise le cluster et charge les donn√©es depuis TinyDB.
    """
    # 1. Initialiser le cluster (code existant)
    # 2. Charger les donn√©es de TinyDB
    # 3. R√©concilier avec l'√©tat actuel
```

**Nouvelles m√©thodes √† ajouter :**
```python
def persist_server(self, server_address, health=None, load=None):
    """
    Persiste les informations d'un serveur dans TinyDB.
    """
    
def persist_model_map(self, model_name, servers):
    """
    Persiste la mapping mod√®le-serveurs dans TinyDB.
    """
```

**Relations :**
- Utilise `database.get_db()` pour acc√©der √† TinyDB
- Appel√© par `proxy.app` au d√©marrage

### 2.2 Initialisation au d√©marrage

**Fichier :** `/src/osync/proxy/app.py`

**T√¢ches :**
- [ ] Modifier l'initialisation pour charger l'√©tat depuis TinyDB
- [ ] Ajouter une logique de r√©conciliation entre l'√©tat persist√© et l'√©tat actuel
- [ ] G√©rer la persistance des nouvelles donn√©es au d√©marrage

## Phase 3 : Int√©gration au moniteur de sant√©

### 3.1 Modification du HealthMonitor

**Fichier :** `/src/osync/proxy/cluster/health.py`

**T√¢ches :**
- [ ] Stocker l'historique de sant√© dans TinyDB
- [ ] Modifier `check_all_servers_health` pour persister les donn√©es
- [ ] Modifier `get_health_report` pour utiliser TinyDB

**M√©thodes √† modifier :**
```python
def check_all_servers_health(self):
    """
    V√©rifie la sant√© de tous les serveurs et persiste les donn√©es.
    """
    # 1. V√©rifier la sant√© (code existant)
    # 2. Persister dans TinyDB
    # 3. Mettre √† jour l'historique en m√©moire (optionnel)
    
def get_health_report(self):
    """
    G√©n√®re un rapport de sant√© complet en utilisant les donn√©es de TinyDB.
    """
    # 1. Requ√™ter TinyDB pour les donn√©es r√©centes
    # 2. G√©n√©rer le rapport
```

**Nouvelles m√©thodes √† ajouter :**
```python
def cleanup_old_stats(self, days_to_keep=30):
    """
    Nettoie les anciennes statistiques au-del√† de la p√©riode sp√©cifi√©e.
    """
```

### 3.2 Extraction de l'historique de sant√©

**T√¢ches :**
- [ ] Cr√©er des m√©thodes pour extraire des statistiques historiques
- [ ] Impl√©menter l'agr√©gation des donn√©es pour diff√©rentes p√©riodes
- [ ] Fournir des m√©thodes d'acc√®s pour l'API et l'interface web

## Phase 4 : Int√©gration aux statistiques de requ√™tes

### 4.1 Modification du module de statistiques

**Fichier :** `/src/osync/proxy/stats.py`

**T√¢ches :**
- [ ] Persister les statistiques dans TinyDB
- [ ] Impl√©menter un m√©canisme d'agr√©gation p√©riodique
- [ ] Ajouter des fonctions pour interroger les statistiques historiques

**M√©thodes √† modifier :**
```python
def update_request_stats(request_type: str, increment: bool = True):
    """
    Met √† jour les statistiques et les persiste dans TinyDB.
    """
    
def get_stats_snapshot():
    """
    R√©cup√®re une image des statistiques depuis TinyDB.
    """
```

**Nouvelles m√©thodes √† ajouter :**
```python
def aggregate_stats(period="hourly"):
    """
    Agr√®ge les statistiques pour la p√©riode sp√©cifi√©e.
    """
    
def get_historical_stats(period="daily", days=7):
    """
    R√©cup√®re les statistiques historiques pour la p√©riode sp√©cifi√©e.
    """
```

## Phase 5 : Collecte d'informations mat√©rielles des n≈ìuds

### 5.1 Extension du service Ollama

**Fichier :** `/src/osync/service.py`

**T√¢ches :**
- [ ] Ajouter une nouvelle m√©thode RPC `GetSystemInfo`
- [ ] Impl√©menter la collecte d'informations syst√®me (CPU, RAM, GPU, stockage)
- [ ] Int√©grer avec le framework gRPC

**Nouvelles m√©thodes √† ajouter :**
```python
def GetSystemInfo(self, request, context):
    """
    Collecte et retourne les informations syst√®me d√©taill√©es du n≈ìud.
    """
```

### 5.2 Mise √† jour du fichier Proto

**Fichier :** `/src/osync/proto/ollama.proto`

**T√¢ches :**
- [ ] D√©finir les messages `SystemInfoRequest` et `SystemInfoResponse`
- [ ] Ajouter la m√©thode RPC au service

**Exemple de d√©finition :**
```protobuf
message SystemInfoRequest {
  bool include_hardware_details = 1;
}

message SystemInfoResponse {
  string system = 1;  // JSON avec les informations syst√®me
  string cpu = 2;     // JSON avec les informations CPU
  string memory = 3;  // JSON avec les informations de m√©moire
  string disk = 4;    // JSON avec les informations de disque
  string gpu = 5;     // JSON avec les informations GPU
}

service OllamaService {
  // Autres m√©thodes RPC existantes
  
  // R√©cup√®re les informations syst√®me d√©taill√©es
  rpc GetSystemInfo(SystemInfoRequest) returns (SystemInfoResponse);
}
```

### 5.3 Int√©gration au ClusterManager

**Fichier :** `/src/osync/proxy/cluster/manager.py`

**T√¢ches :**
- [ ] Ajouter une m√©thode pour r√©cup√©rer les informations syst√®me des n≈ìuds
- [ ] Planifier des collectes p√©riodiques d'informations
- [ ] Persister les informations dans TinyDB

## Phase 6 : API et interface utilisateur

### 6.1 Extension de l'API

**Fichier :** `/src/osync/proxy/api/routes.py`

**T√¢ches :**
- [ ] Ajouter des endpoints pour acc√©der aux donn√©es persist√©es
- [ ] Fournir des m√©thodes d'agr√©gation et de filtrage
- [ ] Documenter l'API avec Swagger

**Endpoints √† ajouter :**
```
GET /api/v1/servers/history?server={server}&metric={metric}&period={period}
GET /api/v1/stats/requests?period={period}&type={type}
GET /api/v1/nodes/hardware?server={server}
```

### 6.2 Mise √† jour de l'interface web

**Fichiers :** Divers templates dans `/src/osync/proxy/web/templates/`

**T√¢ches :**
- [ ] Ajouter des visualisations pour les donn√©es historiques
- [ ] Cr√©er une page d√©di√©e aux m√©triques mat√©rielles
- [ ] Am√©liorer la page de sant√© avec des graphiques bas√©s sur les donn√©es persist√©es

## Phase 7 : Tests et optimisation

### 7.1 Tests unitaires et d'int√©gration

**T√¢ches :**
- [ ] √âcrire des tests unitaires pour `DatabaseManager`
- [ ] Tester la r√©cup√©ration apr√®s red√©marrage
- [ ] Tester les performances avec diff√©rentes charges de donn√©es

### 7.2 Optimisation des performances

**T√¢ches :**
- [ ] Mettre en place des index dans TinyDB
- [ ] Optimiser les requ√™tes fr√©quentes
- [ ] Impl√©menter un m√©canisme de mise en cache pour r√©duire les acc√®s √† la base de donn√©es

### 7.3 Documentation

**T√¢ches :**
- [ ] Documenter l'architecture de persistance
- [ ] Fournir des exemples d'utilisation
- [ ] Mettre √† jour le README avec les nouvelles fonctionnalit√©s

## Suivi du progr√®s

| Phase | T√¢che | Statut | Date | Notes |
|-------|-------|--------|------|-------|
| 1.1 | Classe d'abstraction DatabaseManager | ‚úÖ | 2025-04-30 | Impl√©mentation initiale compl√®te |
| 1.2 | Ajout de la d√©pendance √† TinyDB | ‚úÖ | 2025-04-30 | Ajout√© √† pyproject.toml |
| 1.3 | Sch√©ma des donn√©es | ‚è≥ | - | En cours de finalisation |
| 2.1 | Modification du ClusterManager | üîÑ | - | √Ä commencer |
| ... | ... | ... | ... | ... |

## Structure des d√©pendances entre composants

```mermaid
graph TD
    A[DatabaseManager] --> B[ClusterManager]
    A --> C[HealthMonitor]
    A --> D[RequestStats]
    B --> E[ProxyApp]
    C --> E
    D --> E
    F[OllamaService] --> G[HardwareCollector]
    G --> B
```

## Migration future vers d'autres syst√®mes de base de donn√©es

L'architecture a √©t√© con√ßue pour faciliter une migration future vers d'autres syst√®mes de base de donn√©es plus robustes. Voici les √©tapes cl√©s pour une telle migration :

1. Cr√©er une nouvelle impl√©mentation de `DatabaseManager` pour le nouveau syst√®me
2. Migrer les donn√©es depuis TinyDB
3. Remplacer les instances `get_db()` par la nouvelle impl√©mentation

Les syst√®mes potentiels pour une migration future incluent :
- SQLite pour une persistance locale plus robuste
- PostgreSQL pour un d√©ploiement en production √† grande √©chelle
- MongoDB pour une architecture distribu√©e

## Conclusion

Cette roadmap fournit un plan d√©taill√© pour l'impl√©mentation progressive de la persistance des donn√©es avec TinyDB dans le projet OLOL. En suivant cette approche modulaire, nous pouvons assurer que chaque composant est correctement int√©gr√© et test√© tout en maintenant la coh√©rence globale du syst√®me.

La conception orient√©e abstraction nous permet √©galement de faciliter une migration future vers d'autres syst√®mes de base de donn√©es si n√©cessaire, tout en maintenant une interface coh√©rente pour les d√©veloppeurs travaillant sur le projet.